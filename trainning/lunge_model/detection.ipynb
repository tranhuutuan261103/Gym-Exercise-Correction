{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dự đoán trạng thái, lỗi sai của động tác Lunge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Thêm autoreload vào để tự động reload lại module nếu có thay đổi code trong module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils.common import load_model, calculate_angle\n",
    "\n",
    "# Drawing helpers\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thực hiện việc dự đoán với các model Scikit learn có độ chính xác cao nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# RF_model.pkl là sau điều chỉnh tham số\n",
    "RF_model = load_model('./best_models/RF.pkl')\n",
    "\n",
    "# Load input scaler\n",
    "input_scaler = load_model(\"./best_models/input_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các landmarks quan trọng\n",
    "![](../../images/landmarks_lunge.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORTANT_LMS = [\n",
    "    \"NOSE\",\n",
    "    \"LEFT_SHOULDER\",\n",
    "    \"RIGHT_SHOULDER\",\n",
    "    \"LEFT_HIP\",\n",
    "    \"RIGHT_HIP\",\n",
    "    \"LEFT_KNEE\",\n",
    "    \"RIGHT_KNEE\",\n",
    "    \"LEFT_ANKLE\",\n",
    "    \"RIGHT_ANKLE\",\n",
    "    \"LEFT_HEEL\",\n",
    "    \"RIGHT_HEEL\",\n",
    "    \"LEFT_FOOT_INDEX\",\n",
    "    \"RIGHT_FOOT_INDEX\"\n",
    "]\n",
    "\n",
    "# Tạo các cột cho dữ liệu đầu vào\n",
    "HEADERS = [\"label\"]\n",
    "for landmark in IMPORTANT_LMS:\n",
    "    for dim in ['x', 'y', 'z']:\n",
    "        HEADERS.append(f\"{landmark.lower()}_{dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_amd_recalculate_landmarks(pose_landmarks):\n",
    "    \"\"\"\n",
    "    Tịnh tiến thân người vào giữa bức hình, đồng thời dời lại trục toạ độ\n",
    "    \"\"\"\n",
    "    hip_center_x = float((pose_landmarks[23].x + pose_landmarks[24].x) / 2)\n",
    "    hip_center_y = float((pose_landmarks[23].y + pose_landmarks[24].y) / 2)\n",
    "\n",
    "    new_center = (0.5, 0.5)\n",
    "    delta_x = new_center[0] - hip_center_x\n",
    "    delta_y = new_center[1] - hip_center_y\n",
    "\n",
    "    # Khởi tạo mảng NumPy với kích thước đã biết trước\n",
    "    data = np.zeros((len(IMPORTANT_LMS), 3))\n",
    "\n",
    "    for idx, landmark in enumerate(IMPORTANT_LMS):\n",
    "        key_point_id = mp_pose.PoseLandmark[landmark].value\n",
    "        key_point = pose_landmarks[key_point_id]\n",
    "        data[idx] = [key_point.x + delta_x - 0.5, key_point.y + delta_y - 0.5, key_point.z]\n",
    "\n",
    "    return data.flatten().tolist()\n",
    "\n",
    "\n",
    "def extract_important_key_points(results) -> list:\n",
    "    key_points = np.zeros((len(IMPORTANT_LMS), 3))  # Khởi tạo mảng NumPy\n",
    "\n",
    "    for idx, lm in enumerate(IMPORTANT_LMS):\n",
    "        # Lấy ra id của key point trên cơ thể người\n",
    "        key_point_id = mp_pose.PoseLandmark[lm].value\n",
    "        key_point = results.pose_landmarks.landmark[key_point_id]\n",
    "        key_points[idx] = [key_point.x, key_point.y, key_point.z]\n",
    "\n",
    "    return key_points.flatten().tolist()\n",
    "\n",
    "def rescale_frame(frame, percent=50):\n",
    "    '''\n",
    "    Rescale a frame to a certain percentage compare to its original frame\n",
    "    '''\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(encode_label: float):\n",
    "    \"\"\"\n",
    "    Chuyển một label được encode thành class tương ứng\n",
    "    \"\"\"\n",
    "    return {\n",
    "        0: \"Down\",\n",
    "        1: \"Middle\",\n",
    "        2: \"Stand\"\n",
    "    }.get(encode_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dùng phương pháp hình học để xác định lỗi sai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_points_to_original(points, image_shape):\n",
    "    return (points[0] * image_shape[0], points[1] * image_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_knee_angle(mp_results, image):\n",
    "    image_shape = (image.shape[1], image.shape[0])\n",
    "    landmarks = mp_results.pose_landmarks.landmark\n",
    "\n",
    "    # Lấy toạ độ của 3 điểm cần thiết (hông, đầu gối, mắt cá chân) cho việc tính góc\n",
    "    left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "    left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "    right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "    right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "    # Tính góc tạo bởi 3 điểm trên ở bên trái và bên phải\n",
    "    left_angle = calculate_angle(rescale_points_to_original(left_hip, image_shape), \n",
    "                                 rescale_points_to_original(left_knee, image_shape), \n",
    "                                 rescale_points_to_original(left_ankle, image_shape))\n",
    "    right_angle = calculate_angle(rescale_points_to_original(right_hip, image_shape),\n",
    "                                    rescale_points_to_original(right_knee, image_shape),\n",
    "                                    rescale_points_to_original(right_ankle, image_shape))\n",
    "\n",
    "    # Vẽ góc lên ảnh\n",
    "    # trong đó 0.5 là font size, (255, 255, 255) là màu, 2 là độ dày của chữ\n",
    "    cv2.putText(image, str(int(left_angle)), \n",
    "                tuple(np.multiply(left_knee, image_shape).astype(int)), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                )\n",
    "    \n",
    "    cv2.putText(image, str(int(right_angle)), \n",
    "                tuple(np.multiply(right_knee, image_shape).astype(int)), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_errors(mp_results):\n",
    "    leg_front = None # Kiểm tra chân nào là chân đang bước lên trước\n",
    "    landmarks = mp_results.pose_landmarks.landmark\n",
    "    if landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y > landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y:\n",
    "        leg_front = \"left\"\n",
    "    else:\n",
    "        leg_front = \"right\"\n",
    "\n",
    "    return leg_front\n",
    "    # Kiểm tra xem gót chân của chân đưa lên có đang nhón lên không\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_2_vector(v1, v2):\n",
    "    \"\"\"\n",
    "    Tính góc giữa 2 vector\n",
    "    \"\"\"\n",
    "    dot = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    cos_theta = dot / (norm_v1 * norm_v2)\n",
    "    # convert to degree\n",
    "    return np.arccos(cos_theta) * 180 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(image):\n",
    "    \"\"\"\n",
    "    Lấy kích thước của ảnh\n",
    "    \"\"\"\n",
    "    return image.shape[1], image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_leg_front(knee_left, knee_right):\n",
    "    \"\"\"\n",
    "    Xác định chân đưa lên trước, dựa vào vị trí của đầu gối trái và đầu gối phải\n",
    "    \"\"\"\n",
    "    if knee_left[1] < knee_right[1]:\n",
    "        return \"left\"\n",
    "    else:\n",
    "        return \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_errors(key_points, image_size):\n",
    "    errors = []\n",
    "\n",
    "    leg_front = define_leg_front(rescale_points_to_original((key_points.left_knee_x[0], key_points.left_knee_y[0]), image_size),\n",
    "                                    rescale_points_to_original((key_points.right_knee_x[0], key_points.right_knee_y[0]), image_size))\n",
    "    \n",
    "    if leg_front == \"left\":\n",
    "        # Define errors for knee\n",
    "        knee_angle_left = 180\n",
    "        knee_angle_left = calculate_angle(\n",
    "                        rescale_points_to_original((key_points.left_hip_x[0], key_points.left_hip_y[0]), image_size),\n",
    "                        rescale_points_to_original((key_points.left_knee_x[0], key_points.left_knee_y[0]), image_size),\n",
    "                        rescale_points_to_original((key_points.left_ankle_x[0], key_points.left_ankle_y[0]), image_size))\n",
    "\n",
    "        if knee_angle_left > 110 or knee_angle_left < 70:\n",
    "            errors.append(\"left knee not square\")\n",
    "\n",
    "        # Define errors for leg\n",
    "        leg_angle = angle_2_vector(\n",
    "            np.array([(key_points.left_knee_x[0] - key_points.left_ankle_x[0]) * image_size[0], \n",
    "                      (key_points.left_knee_y[0] - key_points.left_ankle_y[0]) * image_size[1]]),\n",
    "            np.array([1, 0])\n",
    "        )\n",
    "\n",
    "        if leg_angle < 75 or leg_angle > 105:\n",
    "            errors.append(\"left leg not straight\")\n",
    "    else:\n",
    "        # Define errors for knee\n",
    "        knee_angle_right = 180\n",
    "        knee_angle_right = calculate_angle(\n",
    "                        rescale_points_to_original((key_points.left_hip_x[0], key_points.right_hip_y[0]), image_size),\n",
    "                        rescale_points_to_original((key_points.right_knee_x[0], key_points.right_knee_y[0]), image_size),\n",
    "                        rescale_points_to_original((key_points.right_ankle_x[0], key_points.right_ankle_y[0]), image_size)\n",
    "            )\n",
    "\n",
    "        if knee_angle_right > 110 or knee_angle_right < 70:\n",
    "            errors.append(\"right knee not square\")\n",
    "\n",
    "        # Define errors for leg\n",
    "        leg_angle = angle_2_vector(\n",
    "            np.array([(key_points.right_knee_x[0] - key_points.right_ankle_x[0]) * image_size[0], (key_points.right_knee_y[0] - key_points.right_ankle_y[0]) * image_size[1]]),\n",
    "            np.array([1, 0])\n",
    "        )\n",
    "        if leg_angle < 75 or leg_angle > 105:\n",
    "            errors.append(\"right leg not straight\")\n",
    "\n",
    "    body = angle_2_vector(\n",
    "        np.array([(key_points.left_shoulder_x[0] - key_points.left_hip_x[0]) * image_size[0], (key_points.left_shoulder_y[0] - key_points.left_hip_y[0]) * image_size[1]]),\n",
    "        np.array([1, 0])\n",
    "    )\n",
    "\n",
    "    if body < 75 or body > 105:\n",
    "        errors.append(\"body not straight\")\n",
    "\n",
    "    if errors == []:\n",
    "        return \"OK\"\n",
    "    else:\n",
    "        return \", \".join(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TEST = \"./example.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_TEST)\n",
    "current_stage = \"Unknown\"\n",
    "prediction_probability_threshold = 0.55\n",
    "\n",
    "# Số frame được bỏ qua\n",
    "frame_skip = 1\n",
    "frame_count = 0\n",
    "\n",
    "# Số rep tập được\n",
    "counter = 0\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Bỏ qua frame nếu không phải frame được xử lý\n",
    "        if frame_count % frame_skip != 0:\n",
    "            continue\n",
    "\n",
    "        # resize frame để tăng tốc độ xử lý\n",
    "        image = rescale_frame(image, percent=30)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if not results.pose_landmarks:\n",
    "            print(\"No human found\")\n",
    "            continue\n",
    "\n",
    "        initial_pose_landmarks = copy.deepcopy(results.pose_landmarks)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        # Cần khôi phục lại màu gốc của ảnh\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks and connections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, \n",
    "                                  mp_pose.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(244, 117, 66), thickness=2, circle_radius=2), \n",
    "                                  mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=1))\n",
    "        \n",
    "        # Get landmarks\n",
    "        try:\n",
    "            draw_knee_angle(results, image)\n",
    "            key_points = extract_amd_recalculate_landmarks(results.pose_landmarks.landmark)\n",
    "            X = pd.DataFrame([key_points], columns=HEADERS[1:])\n",
    "            errors = define_errors(X, get_image_size(image))\n",
    "            X = input_scaler.transform(X)\n",
    "\n",
    "            predicted_stage = RF_model.predict(X)[0]\n",
    "            predicted_stage = get_class(predicted_stage)\n",
    "            prediction_probability_max = RF_model.predict_proba(X)[0].max()\n",
    "\n",
    "            if prediction_probability_max >= prediction_probability_threshold:\n",
    "                if predicted_stage == \"Down\" and current_stage == \"Middle\":\n",
    "                    counter += 1\n",
    "                current_stage = predicted_stage\n",
    "\n",
    "            cv2.rectangle(image, (0, 0), (image.shape[1], 60), (245, 117, 16), -1)\n",
    "\n",
    "            # Display probability\n",
    "            cv2.putText(image, \"REP\", (15, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(counter), (20, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display class\n",
    "            cv2.putText(image, \"STAGE\", (100, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, f\"{predicted_stage}, {round(prediction_probability_max, 2)}\", (60, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, \n",
    "                        (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(image, \"ERRORS\", (260, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            if current_stage == \"Down\":\n",
    "                cv2.putText(image, f\"{errors}\", (260, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "        cv2.imshow(\"CV2\", image)\n",
    "        \n",
    "        # Nhấn q để thoát\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
