{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dự đoán trạng thái, lỗi sai của động tác Lunge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm autoreload vào để tự động reload lại module nếu có thay đổi code trong module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from utils.common import load_model, calculate_angle\n",
    "\n",
    "# Drawing helpers\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thực hiện việc dự đoán với các model Scikit learn có độ chính xác cao nhất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF_model.pkl là sau điều chỉnh tham số\n",
    "RF_model = load_model('./best_models/RF_model.pkl')\n",
    "\n",
    "# Load input scaler\n",
    "input_scaler = load_model(\"./best_models/input_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các landmarks quan trọng\n",
    "![](../../images/landmarks_lunge.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORTANT_LMS = [\n",
    "    \"NOSE\",\n",
    "    \"LEFT_SHOULDER\",\n",
    "    \"RIGHT_SHOULDER\",\n",
    "    \"LEFT_HIP\",\n",
    "    \"RIGHT_HIP\",\n",
    "    \"LEFT_KNEE\",\n",
    "    \"RIGHT_KNEE\",\n",
    "    \"LEFT_ANKLE\",\n",
    "    \"RIGHT_ANKLE\",\n",
    "    \"LEFT_HEEL\",\n",
    "    \"RIGHT_HEEL\",\n",
    "    \"LEFT_FOOT_INDEX\",\n",
    "    \"RIGHT_FOOT_INDEX\"\n",
    "]\n",
    "\n",
    "# Tạo các cột cho dữ liệu đầu vào\n",
    "HEADERS = [\"label\"]\n",
    "for landmark in IMPORTANT_LMS:\n",
    "    for dim in ['x', 'y', 'z']:\n",
    "        HEADERS.append(f\"{landmark.lower()}_{dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'body_not_straight': (array([ 3.05175781e-05,  0.00000000e+00,  0.00000000e+00, ...,\n",
      "        0.00000000e+00,  0.00000000e+00, -3.05175781e-05]), 16000), 'left_knee_not_square': (array([ 9.15527344e-05,  3.05175781e-05, -3.05175781e-05, ...,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00]), 16000), 'left_knee_not_square_left_leg_not_straight.mp3': (array([ 2.33984436e-04, -2.06475106e-05, -1.32681394e-04, ...,\n",
      "       -3.36626454e-06,  5.95350366e-06, -5.17866965e-06]), 16000), 'left_knee_not_square_left_leg_not_straight': (array([ 2.44140625e-04, -3.05175781e-05, -1.22070312e-04, ...,\n",
      "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00]), 16000), 'left_leg_not_straight.mp3': (array([ 2.69670527e-05, -8.21047797e-06, -5.24136522e-05, ...,\n",
      "        2.23762945e-05,  2.72878879e-06,  2.21791415e-05]), 16000), 'left_leg_not_straight': (array([ 3.05175781e-05,  0.00000000e+00, -6.10351562e-05, ...,\n",
      "        3.05175781e-05,  0.00000000e+00,  3.05175781e-05]), 16000), 'left_leg_not_straight_body_not_straight': (array([6.10351562e-05, 3.05175781e-05, 0.00000000e+00, ...,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00]), 16000), 'right_knee_not_square': (array([ 9.15527344e-05,  3.05175781e-05, -3.05175781e-05, ...,\n",
      "       -3.05175781e-05,  0.00000000e+00,  1.83105469e-04]), 16000), 'right_knee_not_square_right_leg_not_straight.mp3': (array([ 1.70287298e-04, -4.37593335e-05, -1.23693098e-04, ...,\n",
      "        2.14498577e-05,  2.57643496e-05, -1.06435466e-04]), 16000), 'right_knee_not_square_right_leg_not_straight': (array([ 1.83105469e-04, -3.05175781e-05, -1.22070312e-04, ...,\n",
      "        3.05175781e-05,  3.05175781e-05, -9.15527344e-05]), 16000), 'right_leg_not_straight.mp3': (array([ 2.68665972e-05, -1.57502200e-06, -1.13022761e-05, ...,\n",
      "        2.14950887e-06,  2.55939358e-06,  1.74118351e-04]), 16000), 'right_leg_not_straight': (array([3.05175781e-05, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "       0.00000000e+00, 0.00000000e+00, 1.83105469e-04]), 16000), 'right_leg_not_straight_body_not_straight': (array([3.05175781e-05, 3.05175781e-05, 0.00000000e+00, ...,\n",
      "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00]), 16000)}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "# Khởi tạo dictionary để lưu các đối tượng audio\n",
    "error_types_audio = {}\n",
    "\n",
    "# Thư mục chứa các file âm thanh\n",
    "folder_path = \"audios\"\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# Duyệt qua các file trong thư mục\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(current_path, folder_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        data, samplerate = sf.read(file_path)\n",
    "        filename = filename.replace(\".wav\", \"\")\n",
    "        error_types_audio[filename] = (data, samplerate)\n",
    "\n",
    "# In dictionary sau khi lưu\n",
    "print(error_types_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_recalculate_landmarks(pose_landmarks):\n",
    "    \"\"\"\n",
    "    Tịnh tiến thân người vào giữa bức hình, đồng thời dời lại trục toạ độ\n",
    "    \"\"\"\n",
    "    hip_center_x = float((pose_landmarks[23].x + pose_landmarks[24].x) / 2)\n",
    "    hip_center_y = float((pose_landmarks[23].y + pose_landmarks[24].y) / 2)\n",
    "\n",
    "    new_center = (0.5, 0.5)\n",
    "    delta_x = new_center[0] - hip_center_x\n",
    "    delta_y = new_center[1] - hip_center_y\n",
    "\n",
    "    # Khởi tạo mảng NumPy với kích thước đã biết trước\n",
    "    data = np.zeros((len(IMPORTANT_LMS), 3))\n",
    "\n",
    "    for idx, landmark in enumerate(IMPORTANT_LMS):\n",
    "        key_point_id = mp_pose.PoseLandmark[landmark].value\n",
    "        key_point = pose_landmarks[key_point_id]\n",
    "        data[idx] = [key_point.x + delta_x - 0.5, key_point.y + delta_y - 0.5, key_point.z]\n",
    "\n",
    "    return data.flatten().tolist()\n",
    "\n",
    "\n",
    "def extract_important_key_points(results) -> list:\n",
    "    key_points = np.zeros((len(IMPORTANT_LMS), 3))  # Khởi tạo mảng NumPy\n",
    "\n",
    "    for idx, lm in enumerate(IMPORTANT_LMS):\n",
    "        # Lấy ra id của key point trên cơ thể người\n",
    "        key_point_id = mp_pose.PoseLandmark[lm].value\n",
    "        key_point = results.pose_landmarks.landmark[key_point_id]\n",
    "        key_points[idx] = [key_point.x, key_point.y, key_point.z]\n",
    "\n",
    "    return key_points.flatten().tolist()\n",
    "\n",
    "def rescale_frame(frame, percent=50):\n",
    "    '''\n",
    "    Rescale a frame to a certain percentage compare to its original frame\n",
    "    '''\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(encode_label: float):\n",
    "    \"\"\"\n",
    "    Chuyển một label được encode thành class tương ứng\n",
    "    \"\"\"\n",
    "    return {\n",
    "        0: \"Down\",\n",
    "        1: \"Middle\",\n",
    "        2: \"Stand\"\n",
    "    }.get(encode_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dùng phương pháp hình học để xác định lỗi sai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_points_to_original(points, image_shape):\n",
    "    return (points[0] * image_shape[0], points[1] * image_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_knee_angle(mp_results, image):\n",
    "    image_shape = (image.shape[1], image.shape[0])\n",
    "    landmarks = mp_results.pose_landmarks.landmark\n",
    "\n",
    "    # Lấy toạ độ của 3 điểm cần thiết (hông, đầu gối, mắt cá chân) cho việc tính góc\n",
    "    left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "    left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "    right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "    right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "    # Tính góc tạo bởi 3 điểm trên ở bên trái và bên phải\n",
    "    left_angle = calculate_angle(rescale_points_to_original(left_hip, image_shape), \n",
    "                                 rescale_points_to_original(left_knee, image_shape), \n",
    "                                 rescale_points_to_original(left_ankle, image_shape))\n",
    "    right_angle = calculate_angle(rescale_points_to_original(right_hip, image_shape),\n",
    "                                    rescale_points_to_original(right_knee, image_shape),\n",
    "                                    rescale_points_to_original(right_ankle, image_shape))\n",
    "\n",
    "    # Vẽ góc lên ảnh\n",
    "    # trong đó 0.5 là font size, (255, 255, 255) là màu, 2 là độ dày của chữ\n",
    "    cv2.putText(image, str(int(left_angle)), \n",
    "                tuple(np.multiply(left_knee, image_shape).astype(int)), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                )\n",
    "    \n",
    "    cv2.putText(image, str(int(right_angle)), \n",
    "                tuple(np.multiply(right_knee, image_shape).astype(int)), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_2_vector(v1, v2):\n",
    "    \"\"\"\n",
    "    Tính góc giữa 2 vector\n",
    "    \"\"\"\n",
    "    dot = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    cos_theta = dot / (norm_v1 * norm_v2)\n",
    "    # convert to degree\n",
    "    return np.arccos(cos_theta) * 180 / np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_size(image):\n",
    "    \"\"\"\n",
    "    Lấy kích thước của ảnh\n",
    "    \"\"\"\n",
    "    return image.shape[1], image.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_leg_front(knee_left, knee_right):\n",
    "    \"\"\"\n",
    "    Xác định chân đưa lên trước, dựa vào vị trí của đầu gối trái và đầu gối phải\n",
    "    \"\"\"\n",
    "    if knee_left[1] < knee_right[1]:\n",
    "        return \"left\"\n",
    "    else:\n",
    "        return \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_errors(key_points, image_size):\n",
    "    errors = []\n",
    "\n",
    "    leg_front = define_leg_front(\n",
    "        rescale_points_to_original(\n",
    "            (key_points.left_knee_x[0], key_points.left_knee_y[0]), image_size\n",
    "        ),\n",
    "        rescale_points_to_original(\n",
    "            (key_points.right_knee_x[0], key_points.right_knee_y[0]), image_size\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    if leg_front == \"left\":\n",
    "        knee_angle_left = calculate_angle(\n",
    "            rescale_points_to_original(\n",
    "                (key_points.left_hip_x[0], key_points.left_hip_y[0]), image_size\n",
    "            ),\n",
    "            rescale_points_to_original(\n",
    "                (key_points.left_knee_x[0], key_points.left_knee_y[0]), image_size\n",
    "            ),\n",
    "            rescale_points_to_original(\n",
    "                (key_points.left_ankle_x[0], key_points.left_ankle_y[0]), image_size\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if knee_angle_left > 110 or knee_angle_left < 70:\n",
    "            errors.append(\"left knee not square\")\n",
    "\n",
    "        leg_angle = angle_2_vector(\n",
    "            np.array(\n",
    "                [\n",
    "                    (key_points.left_knee_x[0] - key_points.left_ankle_x[0])\n",
    "                    * image_size[0],\n",
    "                    (key_points.left_knee_y[0] - key_points.left_ankle_y[0])\n",
    "                    * image_size[1],\n",
    "                ]\n",
    "            ),\n",
    "            np.array([1, 0]),\n",
    "        )\n",
    "\n",
    "        if leg_angle < 75 or leg_angle > 105:\n",
    "            print(leg_angle)\n",
    "            errors.append(\"left leg not straight\")\n",
    "    else:\n",
    "        knee_angle_right = calculate_angle(\n",
    "            rescale_points_to_original(\n",
    "                (key_points.left_hip_x[0], key_points.right_hip_y[0]), image_size\n",
    "            ),\n",
    "            rescale_points_to_original(\n",
    "                (key_points.right_knee_x[0], key_points.right_knee_y[0]), image_size\n",
    "            ),\n",
    "            rescale_points_to_original(\n",
    "                (key_points.right_ankle_x[0], key_points.right_ankle_y[0]), image_size\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        if knee_angle_right > 110 or knee_angle_right < 70:\n",
    "            errors.append(\"right knee not square\")\n",
    "\n",
    "        # Define errors for leg\n",
    "        leg_angle = angle_2_vector(\n",
    "            np.array(\n",
    "                [\n",
    "                    (key_points.right_knee_x[0] - key_points.right_ankle_x[0])\n",
    "                    * image_size[0],\n",
    "                    (key_points.right_knee_y[0] - key_points.right_ankle_y[0])\n",
    "                    * image_size[1],\n",
    "                ]\n",
    "            ),\n",
    "            np.array([1, 0]),\n",
    "        )\n",
    "        print(leg_angle)\n",
    "        if leg_angle < 75 or leg_angle > 105:\n",
    "            errors.append(\"right leg not straight\")\n",
    "\n",
    "    body = angle_2_vector(\n",
    "        np.array(\n",
    "            [\n",
    "                (key_points.left_shoulder_x[0] - key_points.left_hip_x[0])\n",
    "                * image_size[0],\n",
    "                (key_points.left_shoulder_y[0] - key_points.left_hip_y[0])\n",
    "                * image_size[1],\n",
    "            ]\n",
    "        ),\n",
    "        np.array([1, 0]),\n",
    "    )\n",
    "\n",
    "    if body < 75 or body > 105:\n",
    "        errors.append(\"body not straight\")\n",
    "\n",
    "    if errors == []:\n",
    "        return \"None\"\n",
    "    else:\n",
    "        return \", \".join(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_TEST = \"./example.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import sounddevice as sd\n",
    "\n",
    "is_playing = False\n",
    "\n",
    "def play_audio(data, samplerate):\n",
    "    global is_playing\n",
    "    is_playing = True\n",
    "    sd.play(data, samplerate)\n",
    "    sd.wait()\n",
    "    is_playing = False\n",
    "\n",
    "# Hàm bắt đầu một luồng để phát âm thanh\n",
    "def start_audio_thread(data, samplerate):\n",
    "    threading.Thread(target=play_audio, args=(data, samplerate,), daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_knee_not_square\n",
      "115.5762113792301\n",
      "left_leg_not_straight\n",
      "105.49050556112951\n",
      "right_leg_not_straight\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "cap = cv2.VideoCapture(VIDEO_TEST)\n",
    "current_stage = \"Unknown\"\n",
    "prediction_probability_threshold = 0.55\n",
    "\n",
    "# Số frame được bỏ qua\n",
    "frame_skip = 1\n",
    "frame_count = 0\n",
    "\n",
    "# Số rep tập được\n",
    "counter = 0\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Bỏ qua frame nếu không phải frame được xử lý\n",
    "        if frame_count % frame_skip != 0:\n",
    "            continue\n",
    "\n",
    "        # resize frame để tăng tốc độ xử lý\n",
    "        image = rescale_frame(image, percent=50)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "\n",
    "        if not results.pose_landmarks:\n",
    "            print(\"No human found\")\n",
    "            continue\n",
    "\n",
    "        initial_pose_landmarks = copy.deepcopy(results.pose_landmarks)\n",
    "        image.flags.writeable = True\n",
    "\n",
    "        # Cần khôi phục lại màu gốc của ảnh\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks and connections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, \n",
    "                                  mp_pose.POSE_CONNECTIONS, \n",
    "                                  mp_drawing.DrawingSpec(color=(244, 117, 66), thickness=2, circle_radius=2), \n",
    "                                  mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=1))\n",
    "        \n",
    "        # Get landmarks\n",
    "        try:\n",
    "            draw_knee_angle(results, image)\n",
    "            key_points = extract_and_recalculate_landmarks(results.pose_landmarks.landmark)\n",
    "            X = pd.DataFrame([key_points], columns=HEADERS[1:])\n",
    "            X_original = copy.deepcopy(X)\n",
    "            X = input_scaler.transform(X)\n",
    "\n",
    "            predicted_stage = RF_model.predict(X)[0]\n",
    "            predicted_stage = get_class(predicted_stage)\n",
    "            prediction_probability_max = RF_model.predict_proba(X)[0].max()\n",
    "\n",
    "            if prediction_probability_max >= prediction_probability_threshold:\n",
    "                if predicted_stage == \"Down\" and current_stage == \"Middle\":\n",
    "                    counter += 1\n",
    "                current_stage = predicted_stage\n",
    "\n",
    "            if current_stage == \"Down\" and not is_playing:\n",
    "                errors = define_errors(X_original, get_image_size(image))\n",
    "                errors_list = errors.split(\", \")\n",
    "                if len(errors_list) == 1:\n",
    "                    error_types = errors_list[0].replace(\" \", \"_\")\n",
    "                elif len(errors_list) == 2:\n",
    "                    error_types = \"_\".join(errors_list).replace(\" \", \"_\")\n",
    "                else:\n",
    "                    error_types = \"_\".join([errors_list[0], errors_list[1]]).replace(\" \", \"_\")\n",
    "                \n",
    "                if errors != \"None\" and error_types in error_types_audio and not is_playing:\n",
    "                    print(error_types)\n",
    "                    start_audio_thread(*error_types_audio[error_types])\n",
    "\n",
    "            cv2.rectangle(image, (0, 0), (image.shape[1], 60), (245, 117, 16), -1)\n",
    "\n",
    "            # Display probability\n",
    "            cv2.putText(image, \"REP\", (15, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(counter), (20, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Display class\n",
    "            cv2.putText(image, \"STAGE\", (100, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, f\"{predicted_stage}, {round(prediction_probability_max, 2)}\", (60, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, \n",
    "                        (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(image, \"ERRORS\", (260, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            if current_stage == \"Down\":\n",
    "                cv2.putText(image, f\"{errors}\", (260, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "        cv2.imshow(\"CV2\", image)\n",
    "        \n",
    "        # Nhấn q để thoát\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
